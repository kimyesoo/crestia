#!/usr/bin/env python3
"""
process_sheets_hybrid.py - ë„¤ì´ë²„ ì§€ì‹ì¸ Q&A ë°ì´í„° ì •ì œ ìŠ¤í¬ë¦½íŠ¸

Google Sheetsì˜ Sheet2ì—ì„œ ì§€ì‹ì¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€,
Groq API (Llama 3.3)ë¥¼ ì‚¬ìš©í•´ 3ë‹¨ê³„ AI ì²˜ë¦¬ í›„ ê³ í’ˆì§ˆ Q&Aë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

3ë‹¨ê³„ ì²˜ë¦¬:
1. Relevance Filter (ì„ ë³„) - í¬ë ˆ ê´€ë ¨ ì—¬ë¶€ í™•ì¸
2. Fact Check & Correction (ê²€ì¦) - Knowledge Base ê¸°ì¤€ êµì •
3. Reformatting (ê°€ê³µ) - ì´ˆë³´ì ì§ˆë¬¸ + ê³ ì¸ë¬¼ ë‹µë³€ ìŠ¤íƒ€ì¼ë¡œ ì¬êµ¬ì„±
"""

import os
import json
import time
import re
from datetime import datetime
from typing import Optional, Dict, List, Any

# ============================================
# í™˜ê²½ë³€ìˆ˜ / API í‚¤ ì„¤ì •
# ============================================
# Groq API Key (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
GROQ_API_KEY = os.environ.get("XAI_API_KEY", os.environ.get("GROQ_API_KEY", ""))
GROQ_BASE_URL = "https://api.groq.com/openai/v1"
GROQ_MODEL = "llama-3.3-70b-versatile"

# Google Sheets ì„¤ì •
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "")
SHEET_NAME = "Sheet2"  # ì§€ì‹ì¸ ë°ì´í„°ê°€ ìˆëŠ” ì‹œíŠ¸

# ì¶œë ¥ ê²½ë¡œ
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), '..', 'src', 'constants')

# ============================================
# Knowledge Base (ì ˆëŒ€ íŒ©íŠ¸)
# ============================================
KNOWLEDGE_BASE = """
[ì ˆëŒ€ íŒ©íŠ¸ - í¬ë ˆìŠ¤í‹°ë“œ ê²Œì½” ì‚¬ìœ¡ ê¸°ì¤€]

1. ë¦´ë¦¬ í™”ì´íŠ¸ (Lilly White):
   - ìŠˆí¼í¼(ë¦´ë¦¬ x ë¦´ë¦¬)ì€ ì¹˜ì‚¬ ìœ ì „ â†’ êµë°° ì ˆëŒ€ ê¸ˆì§€
   - ë°˜ë“œì‹œ ë…¸ë©€ ë˜ëŠ” ë‹¤ë¥¸ ëª¨í”„ì™€ êµë°°í•´ì•¼ í•¨

2. ë¨¹ì´:
   - ìŠˆí¼í‘¸ë“œ(íŒ¬ê²Œì•„, ë ˆíŒŒì‹œ) + ê³¤ì¶© ë³‘í–‰ ê¶Œì¥
   - ì ¤ë¦¬ë§Œ ê¸‰ì—¬ëŠ” ì˜ì–‘ ë¶ˆê· í˜• â†’ ì˜ëª»ëœ ì •ë³´
   - ê³¼ì¼ì€ ê°„ì‹ ìˆ˜ì¤€ìœ¼ë¡œë§Œ (ë©”ì¸ ì•„ë‹˜)

3. ì¹´í‘¸ì¹˜ë…¸ (Cappuccino):
   - ì„¸ì´ë¸”(Sable)ê³¼ ëŒ€ë¦½ ìœ ì „ì(Allelic) ê´€ê³„
   - ì¹´í‘¸ì¹˜ë…¸ x ì„¸ì´ë¸” = ë£¨ì™(Luwak) ì½¤ë³´
   - ìŠˆí¼ ì¹´í‘¸ì¹˜ë…¸(ë©œë¼ë‹ˆìŠ¤í‹±)ëŠ” ì½§êµ¬ë© ì¶•ì†Œ/ì•ˆêµ¬ ì§ˆí™˜ ìœ„í—˜

4. ë¬¸ìŠ¤í†¤/íŒŒì´ë³¼ë“œ:
   - í¬ë ˆìŠ¤í‹°ë“œ ê²Œì½” ê³µì‹ ëª¨í”„ ì•„ë‹˜
   - ìƒìˆ  ë˜ëŠ” ë‹¤ë¥¸ ì¢… ìš©ì–´ ì°¨ìš© â†’ ì£¼ì˜ í•„ìš”

5. ì˜¨ë„/í™˜ê²½:
   - ì ì • ì˜¨ë„: 22~26Â°C
   - 28Â°C ì´ìƒ: ìœ„í—˜, 30Â°C ì´ìƒ: ì¹˜ëª…ì 
   - ìŠµë„ ì‚¬ì´í´: ë‚® 50-60%, ë°¤ 70-80%
"""

# ============================================
# Groq API í´ë¼ì´ì–¸íŠ¸
# ============================================
def call_groq_llm(prompt: str, system_prompt: str = "") -> Optional[str]:
    """Groq API í˜¸ì¶œ (Llama 3.3)"""
    try:
        import requests
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {GROQ_API_KEY}"
        }
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        payload = {
            "model": GROQ_MODEL,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000
        }
        
        response = requests.post(
            f"{GROQ_BASE_URL}/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )
        response.raise_for_status()
        
        data = response.json()
        return data["choices"][0]["message"]["content"]
        
    except Exception as e:
        print(f"âŒ Groq API ì˜¤ë¥˜: {e}")
        return None


# ============================================
# 3ë‹¨ê³„ AI ì²˜ë¦¬ ë¡œì§
# ============================================

def step1_relevance_filter(title: str, content: str) -> bool:
    """Step 1: ê´€ë ¨ì„± í•„í„° - í¬ë ˆìŠ¤í‹°ë“œ ê²Œì½” ì‚¬ìœ¡ ê´€ë ¨ ì—¬ë¶€ í™•ì¸"""
    
    system_prompt = """ë‹¹ì‹ ì€ íŒŒì¶©ë¥˜ ì»¤ë®¤ë‹ˆí‹° ê´€ë¦¬ìì…ë‹ˆë‹¤.
ì§ˆë¬¸ì´ 'í¬ë ˆìŠ¤í‹°ë“œ ê²Œì½”' ì‚¬ìœ¡ê³¼ ì§ì ‘ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.
ê´€ë ¨ì´ ìˆìœ¼ë©´ "RELEVANT", ì—†ìœ¼ë©´ "SKIP"ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

SKIP ê¸°ì¤€:
- ë‹¨ìˆœ ë¶„ì–‘ í™ë³´/ê´‘ê³ 
- ë‹¤ë¥¸ íŒŒì¶©ë¥˜(ë ˆì˜¤íŒŒë“œ ê²Œì½”, ë³¼íŒŒì´í†¤ ë“±) ì§ˆë¬¸
- í¬ë ˆì™€ ì „í˜€ ê´€ë ¨ì—†ëŠ” ë‚´ìš©
"""
    
    prompt = f"""ë‹¤ìŒ ì§€ì‹ì¸ ì§ˆë¬¸ì´ í¬ë ˆìŠ¤í‹°ë“œ ê²Œì½” ì‚¬ìœ¡ê³¼ ê´€ë ¨ì´ ìˆë‚˜ìš”?

ì œëª©: {title}
ë‚´ìš©: {content}

RELEVANT ë˜ëŠ” SKIP ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    result = call_groq_llm(prompt, system_prompt)
    if result:
        return "RELEVANT" in result.upper()
    return False


def step2_fact_check_and_correct(title: str, content: str) -> Dict[str, Any]:
    """Step 2: ì‚¬ì‹¤ í™•ì¸ ë° êµì •"""
    
    system_prompt = f"""ë‹¹ì‹ ì€ í¬ë ˆìŠ¤í‹°ë“œ ê²Œì½” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ Knowledge Baseë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì§€ì‹ì¸ ë‹µë³€ì˜ ì •í™•ì„±ì„ ê²€ì¦í•˜ê³  ì˜¤ë¥˜ë¥¼ êµì •í•˜ì„¸ìš”.

{KNOWLEDGE_BASE}

íŠ¹íˆ ë‹¤ìŒ ì˜¤ë¥˜ë¥¼ ë°˜ë“œì‹œ êµì •í•˜ì„¸ìš”:
- "ë¦´ë¦¬ë¼ë¦¬ ë¶™ì—¬ë³´ì„¸ìš”" â†’ "ì ˆëŒ€ ì•ˆ ë©ë‹ˆë‹¤(ì¹˜ì‚¬ìœ ì „)"
- "ì ¤ë¦¬ë§Œ ì¤˜ë„ ë©ë‹ˆë‹¤" â†’ "ìŠˆí¼í‘¸ë“œ+ê³¤ì¶© ë³‘í–‰ ê¶Œì¥"
- "ë¬¸ìŠ¤í†¤ ëª¨í”„" â†’ "ê³µì‹ ëª¨í”„ ì•„ë‹˜, ìƒìˆ  ì£¼ì˜"
- "30ë„ê¹Œì§€ ê´œì°®ì•„ìš”" â†’ "28ë„ ì´ìƒ ìœ„í—˜, 30ë„ ì¹˜ëª…ì "
"""

    prompt = f"""ë‹¤ìŒ ì§€ì‹ì¸ Q&Aë¥¼ ë¶„ì„í•˜ê³  êµì •í•˜ì„¸ìš”:

ì œëª©: {title}
ì›ë¬¸: {content}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "has_errors": true/false,
    "error_summary": "ë°œê²¬ëœ ì˜¤ë¥˜ ìš”ì•½ (ì—†ìœ¼ë©´ null)",
    "corrected_answer": "êµì •ëœ ì •í™•í•œ ë‹µë³€"
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    result = call_groq_llm(prompt, system_prompt)
    if result:
        try:
            # JSON ì¶”ì¶œ (```json ë¸”ë¡ ë‚´ë¶€ ë˜ëŠ” ì „ì²´)
            json_match = re.search(r'\{[\s\S]*\}', result)
            if json_match:
                return json.loads(json_match.group())
        except json.JSONDecodeError:
            pass
    
    return {"has_errors": False, "error_summary": None, "corrected_answer": content}


def step3_reformat_qna(title: str, original_content: str, corrected_answer: str) -> Optional[Dict[str, str]]:
    """Step 3: Q&A ì¬í¬ë§· - ì´ˆë³´ì ì§ˆë¬¸ + ê³ ì¸ë¬¼ ë‹µë³€ ìŠ¤íƒ€ì¼"""
    
    system_prompt = """ë‹¹ì‹ ì€ íŒŒì¶©ë¥˜ ì»¤ë®¤ë‹ˆí‹° ì½˜í…ì¸  ì—ë””í„°ì…ë‹ˆë‹¤.
ì§€ì‹ì¸ Q&Aë¥¼ í¬ë ˆìŠ¤í‹°ë“œ ê²Œì½” ì»¤ë®¤ë‹ˆí‹° ìŠ¤íƒ€ì¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.

ì§ˆë¬¸ì í˜ë¥´ì†Œë‚˜: ë‹¤ê¸‰í•˜ê³  ê¶ê¸ˆí•œ ì´ˆë³´ì (ã… ã… , ?? ë“± ê°ì • í‘œí˜„ ì‚¬ìš©)
ë‹µë³€ì í˜ë¥´ì†Œë‚˜: ì¹œì ˆí•˜ê³  ëª…ì¾Œí•œ 'í¬ë ˆ ê³ ì¸ë¬¼' (ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©, í•µì‹¬ ì •ë³´ ê°•ì¡°)
"""

    prompt = f"""ë‹¤ìŒ Q&Aë¥¼ ì»¤ë®¤ë‹ˆí‹° ìŠ¤íƒ€ì¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”:

ì›ë³¸ ì œëª©: {title}
ì›ë³¸ ì§ˆë¬¸: {original_content}
êµì •ëœ ë‹µë³€: {corrected_answer}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "title": "[ì§ˆë¬¸] ì¬êµ¬ì„±ëœ ì œëª© (ê¶ê¸ˆì¦ ìœ ë°œ, 20ì ì´ë‚´)",
    "content": "ì¬êµ¬ì„±ëœ ì§ˆë¬¸ ë³¸ë¬¸ (ì´ˆë³´ì ë§íˆ¬, 100ì ì´ë‚´)",
    "best_answer": "ì¬êµ¬ì„±ëœ ë‹µë³€ (ì¹œì ˆí•œ ê³ ì¸ë¬¼ ë§íˆ¬, ì´ëª¨ì§€ í¬í•¨, í•µì‹¬ ì •ë³´ ê°•ì¡°)"
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

    result = call_groq_llm(prompt, system_prompt)
    if result:
        try:
            json_match = re.search(r'\{[\s\S]*\}', result)
            if json_match:
                return json.loads(json_match.group())
        except json.JSONDecodeError:
            pass
    
    return None


# ============================================
# Google Sheets ì—°ë™ (ê°„ë‹¨ ë²„ì „)
# ============================================

def get_sheet_data_mock() -> List[Dict[str, str]]:
    """
    Mock ë°ì´í„° (ì‹¤ì œë¡œëŠ” Google Sheets API ì‚¬ìš©)
    ì‹¤ì œ êµ¬í˜„ ì‹œ gspread ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
    """
    # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°
    return [
        {
            "title": "ë¦´ë¦¬ë¼ë¦¬ êµë°°í•´ë„ ë˜ë‚˜ìš”?",
            "content": "ë¦´ë¦¬ í™”ì´íŠ¸ ì•”ìˆ˜ê°€ ìˆëŠ”ë° ë‘˜ì´ ë¶™ì´ë©´ ë” í•˜ì–€ ì• ê¸°ê°€ ë‚˜ì˜¨ë‹¤ê³  í•´ì„œìš”. í•´ë„ ë ê¹Œìš”?"
        },
        {
            "title": "í¬ë ˆ ë¨¹ì´ë¡œ ì ¤ë¦¬ë§Œ ì¤˜ë„ ë˜ë‚˜ìš”",
            "content": "ìŠˆí¼í‘¸ë“œ ë¹„ì‹¸ì„œ ê·¸ëƒ¥ ê³¤ì¶© ì ¤ë¦¬ë¡œ ì£¼ë ¤ëŠ”ë° ê´œì°®ì„ê¹Œìš”? ë‹µë³€ ë¶€íƒë“œë ¤ìš”"
        },
        {
            "title": "ì¹´í‘¸ì¹˜ë…¸ ëª¨í”„ ì•Œë ¤ì£¼ì„¸ìš”",
            "content": "ì¹´í‘¸ì¹˜ë…¸ë‘ ì„¸ì´ë¸”ì´ ë­ê°€ ë‹¤ë¥¸ì§€ ëª¨ë¥´ê² ì–´ìš”. êµë°°í•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
        },
        {
            "title": "ì—¬ë¦„ì— ì˜¨ë„ 30ë„ ë„˜ì–´ë„ ê´œì°®ë‚˜ìš”?",
            "content": "ì—ì–´ì»¨ì´ ì—†ì–´ì„œ ë°©ì´ 32ë„ê¹Œì§€ ì˜¬ë¼ê°€ëŠ”ë° í¬ë ˆê°€ ë²„í‹¸ ìˆ˜ ìˆì„ê¹Œìš”?"
        },
        {
            "title": "ë¬¸ìŠ¤í†¤ í¬ë ˆ ë¶„ì–‘í•©ë‹ˆë‹¤ (ê´‘ê³ )",
            "content": "ì˜ˆìœ ë¬¸ìŠ¤í†¤ í¬ë ˆ ë¶„ì–‘í•©ë‹ˆë‹¤. ì—°ë½ì£¼ì„¸ìš” 010-xxxx-xxxx"
        }
    ]


def get_sheet_data_real() -> List[Dict[str, str]]:
    """
    Google Sheets APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    gspread ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”: pip install gspread oauth2client
    """
    try:
        import gspread
        from oauth2client.service_account import ServiceAccountCredentials
        
        # Google Sheets API ì¸ì¦
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive"
        ]
        
        # ì„œë¹„ìŠ¤ ê³„ì • JSON í‚¤ íŒŒì¼ ê²½ë¡œ
        creds_path = os.environ.get("GOOGLE_CREDS_PATH", "google_creds.json")
        
        if not os.path.exists(creds_path):
            print("âš ï¸ Google ì¸ì¦ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Mock ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return get_sheet_data_mock()
        
        creds = ServiceAccountCredentials.from_json_keyfile_name(creds_path, scope)
        client = gspread.authorize(creds)
        
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
        sheet = client.open_by_key(GOOGLE_SHEET_ID).worksheet(SHEET_NAME)
        
        # ëª¨ë“  ë ˆì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        records = sheet.get_all_records()
        
        # Column D(3) = ì œëª©, Column E(4) = ë³¸ë¬¸+ë‹µë³€
        data = []
        for row in records:
            # ì»¬ëŸ¼ ì´ë¦„ì— ë”°ë¼ ì¡°ì • í•„ìš”
            title = row.get("ì œëª©", row.get("title", ""))
            content = row.get("ë³¸ë¬¸", row.get("content", ""))
            
            if title and content:
                data.append({"title": title, "content": content})
        
        return data
        
    except ImportError:
        print("âš ï¸ gspread ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. pip install gspread oauth2client")
        return get_sheet_data_mock()
    except Exception as e:
        print(f"âŒ Google Sheets ì˜¤ë¥˜: {e}")
        return get_sheet_data_mock()


# ============================================
# ë©”ì¸ ì²˜ë¦¬ ë¡œì§
# ============================================

def process_single_qna(title: str, content: str, index: int) -> Optional[Dict[str, Any]]:
    """
    ë‹¨ì¼ Q&A ì²˜ë¦¬ (3ë‹¨ê³„)
    
    ë°ì´í„° ë¬´ê²°ì„± ì •ì±… (Honesty Policy):
    - comment_count: ì‹¤ì œ ë‹µë³€ ìˆ˜ (1 or 0), NOT random
    - views: ëœë¤ (50~2000) - í™œì„±í™”ë¥¼ ìœ„í•´ ìœ ì§€
    - likes: ì¡°íšŒìˆ˜ì˜ 3~5% ë¹„ìœ¨ë¡œ ì„¤ì • (ë¦¬ì–¼í•œ ëŠë‚Œ)
    - is_solved: ë‹µë³€ì´ ìˆìœ¼ë©´ True
    
    í”„ë¡ íŠ¸ì—”ë“œ íŒíŠ¸:
    - ëŒ“ê¸€ ìˆ˜ ëŒ€ì‹  'ì¡°íšŒìˆ˜'ì™€ 'ì¢‹ì•„ìš”'ë¥¼ ê°•ì¡°í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”.
    - ë‹µë³€ì´ 1ê°œë¼ë„ ìˆìœ¼ë©´ 'âœ… í•´ê²°ë¨' ë°°ì§€ë¥¼ ë¶™ì´ì„¸ìš”.
    - íŒ©íŠ¸ì²´í¬ëœ ë‹µë³€ì—ëŠ” 'ğŸ”¬ ê²€ì¦ë¨' ë°°ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
    """
    import random
    
    print(f"\n{'='*50}")
    print(f"ğŸ“ ì²˜ë¦¬ ì¤‘ [{index}]: {title[:30]}...")
    
    # Step 1: ê´€ë ¨ì„± í•„í„°
    print("  Step 1: ê´€ë ¨ì„± í™•ì¸...", end=" ")
    if not step1_relevance_filter(title, content):
        print("âŒ SKIP (ê´€ë ¨ ì—†ìŒ)")
        return None
    print("âœ… RELEVANT")
    
    # Step 2: ì‚¬ì‹¤ í™•ì¸ ë° êµì •
    print("  Step 2: íŒ©íŠ¸ ì²´í¬...", end=" ")
    fact_check = step2_fact_check_and_correct(title, content)
    if fact_check.get("has_errors"):
        print(f"âš ï¸ êµì •ë¨: {fact_check.get('error_summary', '')[:30]}")
    else:
        print("âœ… ì •í™•í•¨")
    
    corrected_answer = fact_check.get("corrected_answer", content)
    
    # Step 3: ì¬í¬ë§·
    print("  Step 3: ìŠ¤íƒ€ì¼ ë³€í™˜...", end=" ")
    formatted = step3_reformat_qna(title, content, corrected_answer)
    if formatted:
        print("âœ… ì™„ë£Œ")
        
        # === Honesty Policy: í˜„ì‹¤ì ì¸ ë©”íŠ¸ë¦­ ìƒì„± ===
        # ì¡°íšŒìˆ˜: 50~2000 ëœë¤ (ì§ˆë¬¸ í¥ë¯¸ë„ì— ë”°ë¼)
        views = random.randint(50, 2000)
        
        # ì¢‹ì•„ìš”: ì¡°íšŒìˆ˜ì˜ 3~5% (ë¦¬ì–¼í•œ ë°˜ì‘ë¥ )
        like_rate = random.uniform(0.03, 0.05)
        likes = max(5, int(views * like_rate))
        
        # ëŒ“ê¸€ ìˆ˜: ì‹¤ì œ ë‹µë³€ ìˆ˜ (ì •ì§í•œ ê°’)
        # best_answerê°€ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0
        has_answer = bool(formatted.get("best_answer"))
        comment_count = 1 if has_answer else 0
        
        # í•´ê²° ìƒíƒœ: ë‹µë³€ì´ ìˆìœ¼ë©´ í•´ê²°ë¨
        is_solved = has_answer
        
        return {
            "id": f"kin-{index}",
            "source": "naver_kin",
            "original_title": title,
            "processed": {
                **formatted,
                # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•  ë©”íŠ¸ë¦­
                "views": views,
                "likes": likes,
                "comment_count": comment_count,
                "is_solved": is_solved,
                # ë‹‰ë„¤ì„ (ì¶”í›„ ë‹¤ì–‘í™” ê°€ëŠ¥)
                "author": random.choice([
                    "ì™•ì´ˆë³´ë¸Œë¦¬ë”", "í¬ë ˆì…ë¬¸ì", "ë„ë§ˆë±€ë‰´ë¹„", "íŒŒì¶©ë¥˜ì´ˆë³´ë§˜",
                    "ê¶ê¸ˆì´ê°€ë“", "ê²Œì½”ì‹œì‘", "í¬ë ˆì‚¬ë‘í•´", "ì´ˆë³´ì‚¬ìœ¡ì‚¬"
                ])
            },
            "fact_checked": fact_check.get("has_errors", False),
            "processed_at": datetime.now().isoformat()
        }
    else:
        print("âŒ ì‹¤íŒ¨")
        return None


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ¦ ë„¤ì´ë²„ ì§€ì‹ì¸ Q&A ì²˜ë¦¬ ì‹œì‘")
    print(f"   Knowledge Base ì ìš©ë¨")
    print(f"   3ë‹¨ê³„ AI ì²˜ë¦¬: ì„ ë³„ â†’ ê²€ì¦ â†’ ê°€ê³µ\n")
    
    # API í‚¤ í™•ì¸
    if not GROQ_API_KEY:
        print("âŒ GROQ_API_KEY ë˜ëŠ” XAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        print("   ì˜ˆ: set XAI_API_KEY=your-groq-api-key")
        return
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Mock ë˜ëŠ” ì‹¤ì œ)
    use_real_sheets = os.environ.get("USE_REAL_SHEETS", "false").lower() == "true"
    
    if use_real_sheets:
        print("ğŸ“Š Google Sheetsì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        raw_data = get_sheet_data_real()
    else:
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš© ì¤‘...")
        raw_data = get_sheet_data_mock()
    
    print(f"   ì´ {len(raw_data)}ê°œ í•­ëª© ë°œê²¬\n")
    
    # ì²˜ë¦¬
    processed_items = []
    skipped_count = 0
    
    for i, item in enumerate(raw_data, 1):
        result = process_single_qna(item["title"], item["content"], i)
        
        if result:
            processed_items.append(result)
        else:
            skipped_count += 1
        
        # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
        time.sleep(1)
    
    # ê²°ê³¼ ì €ì¥
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_path = os.path.join(OUTPUT_DIR, "community_kin_processed.json")
    
    output_data = {
        "source": "Naver Kin via Groq Llama 3.3 Processing",
        "processed_at": datetime.now().isoformat(),
        "total_raw": len(raw_data),
        "total_processed": len(processed_items),
        "total_skipped": skipped_count,
        "items": processed_items
    }
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*50}")
    print("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   - ì›ë³¸ ë°ì´í„°: {len(raw_data)}ê°œ")
    print(f"   - ì²˜ë¦¬ ì™„ë£Œ: {len(processed_items)}ê°œ")
    print(f"   - ê±´ë„ˆëœ€: {skipped_count}ê°œ")
    print(f"   - ì €ì¥ ìœ„ì¹˜: {output_path}")
    
    # ìƒ˜í”Œ ì¶œë ¥
    if processed_items:
        print(f"\nğŸ“Œ ìƒ˜í”Œ ê²°ê³¼:")
        sample = processed_items[0]["processed"]
        print(f"   ì œëª©: {sample.get('title', 'N/A')}")
        print(f"   ì§ˆë¬¸: {sample.get('content', 'N/A')[:50]}...")
        print(f"   ë‹µë³€: {sample.get('best_answer', 'N/A')[:50]}...")


if __name__ == "__main__":
    main()
